# 参考文献

1. 李航 《统计学习方法》

2. 周志华 《机器学习》

逻辑回归

3. http://blog.csdn.net/han_xiaoyang/article/details/49332321

Boosting & AdaBoost & GBDT & XGBoost

4. http://blog.jobbole.com/88193/

5. http://www.cnblogs.com/pinard/p/6133937.html

6. http://blog.csdn.net/v_july_v/article/details/40718799

7. http://blog.csdn.net/sb19931201/article/details/52506157

8. http://wepon.me/files/gbdt.pdf

9. http://www.cnblogs.com/pinard/p/6140514.html

10. http://blog.csdn.net/shine19930820/article/details/65633436

11. https://plushunter.github.io/2017/01/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%B3%BB%E5%88%97%EF%BC%887%EF%BC%89%EF%BC%9AGBDT/

12. http://www.52caml.com/head_first_ml/ml-chapter6-boosting-family/

13. http://blog.csdn.net/a1b2c3d4123456/article/details/52849091

14. http://blog.csdn.net/a358463121/article/details/68617389

15. http://blog.csdn.net/a819825294/article/details/51206410

16.Xgboost论文 http://cran.fhcrc.org/web/packages/xgboost/vignettes/xgboost.pdf

17.陈天奇的boosting tree的ppt http://homes.cs.washington.edu/~tqchen/pdf/BoostedTree.pdf

最大熵：

18. http://blog.csdn.net/v_july_v/article/details/40508465

19. https://www.zybuluo.com/frank-shaw/note/108124

20. https://en.wikipedia.org/wiki/Entropy_(information_theory)

21. http://blog.sina.com.cn/s/blog_6920072701010gw6.html

22. https://en.wikipedia.org/wiki/Jensen%27s_inequality

23. http://www.cs.cmu.edu/~aberger/pdf/scaling.pdf

24. http://www.ueltschi.org/teaching/chapShannon.pdf

25. http://math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf

EM:

26. http://www.cnblogs.com/jerrylead/archive/2011/04/06/2006936.html

27. http://www.jianshu.com/p/1121509ac1dc

28. http://cs229.stanford.edu/notes/cs229-notes8.pdf

29. https://www.zhihu.com/question/27976634

KKT与对偶问题

30. http://blog.pluskid.org/?p=702

31. http://www.cnblogs.com/ooon/p/5723725.html

32. http://www.cnblogs.com/ooon/p/5721119.html

Hibert Space

33. http://www.cnblogs.com/ben-ben/articles/3391781.html

34. http://blog.csdn.net/y954877035/article/details/52150151

35. http://blog.sina.com.cn/s/blog_6163bdeb0102edrl.html

SVM

36. http://blog.csdn.net/v_july_v/article/details/7624837

37. http://www.cnblogs.com/vivounicorn/archive/2010/12/13/1904720.html

38. https://www.cnblogs.com/liqizhou/archive/2012/05/11/2495788.html

39. http://blog.pluskid.org/?page_id=683

40. http://blog.csdn.net/haolexiao/article/details/72171523?utm_source=itdadao&utm_medium=referral

41. http://songcy.net/posts/story-of-basis-and-kernel-part-2/

42. https://www.cnblogs.com/jerrylead/archive/2011/03/18/1988406.html

43. http://blog.csdn.net/luoshixian099/article/details/51227754

Bayes

44. 理解全概率公式与贝叶斯公式 http://blog.csdn.net/luc9910/article/details/54377626

45. 全概率公式、贝叶斯公式推导过程 https://www.cnblogs.com/ohshit/p/5629581.html

46. 从贝叶斯方法谈到贝叶斯网络 http://blog.csdn.net/v_july_v/article/details/40984699

HMM

47. 隐马尔可夫模型 http://www.hankcs.com/ml/hidden-markov-model.html

48. 隐马尔可夫模型之Baum-Welch算法详解 https://blog.csdn.net/u014688145/article/details/53046765?locationNum=7&fps=1

49. 隐马尔可夫模型（HMM）攻略 https://blog.csdn.net/likelet/article/details/7056068

CRF

50. 条件随机场（CRF） https://blog.csdn.net/a819825294/article/details/53893231

51. 条件随机场 http://www.hankcs.com/ml/conditional-random-field.html
