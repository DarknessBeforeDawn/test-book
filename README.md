# 参考文献

1. 李航 《统计学习方法》

2. 周志华 《机器学习》

逻辑回归

3. http://blog.csdn.net/han_xiaoyang/article/details/49332321

Boosting & AdaBoost & GBDT & XGBoost

4. http://blog.jobbole.com/88193/

5. http://www.cnblogs.com/pinard/p/6133937.html

6. http://blog.csdn.net/v_july_v/article/details/40718799

7. http://blog.csdn.net/sb19931201/article/details/52506157

8. http://wepon.me/files/gbdt.pdf

9. http://www.cnblogs.com/pinard/p/6140514.html

10. http://blog.csdn.net/shine19930820/article/details/65633436

11. https://plushunter.github.io/2017/01/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%B3%BB%E5%88%97%EF%BC%887%EF%BC%89%EF%BC%9AGBDT/

12. http://www.52caml.com/head_first_ml/ml-chapter6-boosting-family/

13. http://blog.csdn.net/a1b2c3d4123456/article/details/52849091

14. http://blog.csdn.net/a358463121/article/details/68617389

15. http://blog.csdn.net/a819825294/article/details/51206410

16.Xgboost论文 http://cran.fhcrc.org/web/packages/xgboost/vignettes/xgboost.pdf

17.陈天奇的boosting tree的ppt http://homes.cs.washington.edu/~tqchen/pdf/BoostedTree.pdf

最大熵：

18. http://blog.csdn.net/v_july_v/article/details/40508465

19. https://www.zybuluo.com/frank-shaw/note/108124

20. https://en.wikipedia.org/wiki/Entropy_(information_theory)

21. http://blog.sina.com.cn/s/blog_6920072701010gw6.html

22. https://en.wikipedia.org/wiki/Jensen%27s_inequality

23. http://www.cs.cmu.edu/~aberger/pdf/scaling.pdf

24. http://www.ueltschi.org/teaching/chapShannon.pdf

25. http://math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf

EM:

26. http://www.cnblogs.com/jerrylead/archive/2011/04/06/2006936.html

27. http://www.jianshu.com/p/1121509ac1dc

28. http://cs229.stanford.edu/notes/cs229-notes8.pdf

29. https://www.zhihu.com/question/27976634

